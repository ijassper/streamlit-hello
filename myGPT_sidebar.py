from openai import OpenAI, RateLimitError
import streamlit as st

# í˜ì´ì§€ ì„¤ì • ë° ì»¤ìŠ¤í…€ CSS
st.set_page_config(page_title="ChatGPT Clone", layout="wide")
st.markdown("""
    <style>
    [data-testid="stChatInput"] {
        max-width: 700px;
        margin: 0 auto;
    }
    .centered-input {
        display: flex;
        height: 60vh;
        align-items: center;
        justify-content: center;
        flex-direction: column;
        text-align: center;
    }
    </style>
""", unsafe_allow_html=True)

# API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-3.5-turbo"
if "messages" not in st.session_state:
    st.session_state.messages = []
if "history" not in st.session_state:
    st.session_state.history = []

# ì‚¬ì´ë“œë°”: ëŒ€í™” ê¸°ë¡
with st.sidebar:
    st.header("ğŸ’¬ ëŒ€í™” ê¸°ë¡")
    if st.session_state.history:
        for i, item in enumerate(st.session_state.history):
            if st.button(item["title"], key=f"history_{i}"):
                st.session_state.messages = item["full"]
                st.experimental_rerun()
    if st.button("ğŸ—‘ï¸ ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.history.clear()
        st.session_state.messages.clear()
        st.experimental_rerun()

# ìƒíƒœ ê¸°ë°˜ ë Œë”ë§
if not st.session_state.messages:
    # ğŸ‘‰ ì²« í™”ë©´: ì¤‘ì•™ ì •ë ¬ëœ UI
    st.markdown('<div class="centered-input">', unsafe_allow_html=True)
    st.title("ChatGPT-like Clone")
    user_input = st.chat_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?")
    st.markdown('</div>', unsafe_allow_html=True)

    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        st.experimental_rerun()

else:
    # ğŸ‘‰ ì±„íŒ… í™”ë©´: ëŒ€í™” ë Œë”ë§
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            try:
                stream = client.chat.completions.create(
                    model=st.session_state["openai_model"],
                    messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
                    stream=True,
                )
                full_response = ""
                placeholder = st.empty()
                for chunk in stream:
                    content = getattr(chunk.choices[0].delta, "content", None)
                    if content:
                        full_response += content
                        placeholder.markdown(full_response)

                st.session_state.messages.append({"role": "assistant", "content": full_response})
                summary = prompt[:30] + ("..." if len(prompt) > 30 else "")
                st.session_state.history.append({
                    "title": summary,
                    "full": st.session_state.messages.copy()
                })

            except RateLimitError:
                st.error("âš ï¸ ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
