from openai import OpenAI, RateLimitError
import streamlit as st

st.set_page_config(page_title="ë‚˜ë§Œì˜ ì±—GPT", layout="wide")

st.title("ChatGPT-like clone")

# API í‚¤ ë¡œë“œ
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ëª¨ë¸ ì„¤ì •
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-3.5-turbo"

# ë©”ì‹œì§€ ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ìš”ì•½ ëª©ë¡ (ê°„ë‹¨í•œ ìš”ì•½ë§Œ ì €ì¥)
if "history" not in st.session_state:
    st.session_state.history = []

# ì‚¬ì´ë“œë°”ì— ì±„íŒ… ìš”ì•½ ëª©ë¡ í‘œì‹œ
with st.sidebar:
    st.header("ğŸ’¬ ëŒ€í™” ê¸°ë¡")
    if st.session_state.history:
        for i, item in enumerate(st.session_state.history):
            if st.button(item, key=f"history_{i}"):
                # ê¸°ë¡ì„ í´ë¦­í•˜ë©´ í•´ë‹¹ ë‚´ìš©ì„ ë©”ì‹œì§€ë¡œ ë³µì›
                st.session_state.messages = item["full"]
                st.experimental_rerun()
    if st.button("ğŸ—‘ï¸ ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.history.clear()
        st.session_state.messages.clear()
        st.experimental_rerun()

# ì´ì „ ë©”ì‹œì§€ ë Œë”ë§
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("What is up?"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì²˜ë¦¬
    with st.chat_message("assistant"):
        try:
            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
            stream = client.chat.completions.create(
                model=st.session_state["openai_model"],
                messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
                stream=True,
            )

            # ì‘ë‹µ ì ì°¨ ì¶œë ¥ ë° ëˆ„ì 
            full_response = ""
            placeholder = st.empty()
            for chunk in stream:
                content = getattr(chunk.choices[0].delta, "content", None)
                if content:
                    full_response += content
                    placeholder.markdown(full_response)

            # ì‘ë‹µ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": full_response})

            # ìš”ì•½ ì €ì¥ (ì‚¬ì´ë“œë°”ìš©)
            summary = prompt[:30] + ("..." if len(prompt) > 30 else "")
            st.session_state.history.append({
                "title": summary,
                "full": st.session_state.messages.copy()
            })

        except RateLimitError:
            st.error("âš ï¸ ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        except Exception as e:
            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
