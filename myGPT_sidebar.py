from openai import OpenAI, RateLimitError
import streamlit as st

st.set_page_config(page_title="ChatGPT Clone", layout="wide")

# âœ… CSS ìŠ¤íƒ€ì¼
st.markdown("""
    <style>
    .centered-input {
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        height: 80vh;
        text-align: center;
    }
    .centered-input input {
        width: 500px !important;
        text-align: center;
    }
    </style>
""", unsafe_allow_html=True)

# âœ… ì„¸ì…˜ ìƒíƒœ
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-3.5-turbo"
if "messages" not in st.session_state:
    st.session_state.messages = []
if "history" not in st.session_state:
    st.session_state.history = []

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# âœ… ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ’¬ ëŒ€í™” ê¸°ë¡")
    if st.session_state.history:
        for i, item in enumerate(st.session_state.history):
            if st.button(item["title"], key=f"history_{i}"):
                st.session_state.messages = item["full"]
                st.experimental_rerun()
    if st.button("ğŸ—‘ï¸ ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.history.clear()
        st.session_state.messages.clear()
        st.experimental_rerun()

# âœ… ì²« ëŒ€í™” ì „: í™”ë©´ ì¤‘ì•™ ì…ë ¥ì°½ ì‚¬ìš©
if len(st.session_state.messages) == 0:
    st.markdown('<div class="centered-input">', unsafe_allow_html=True)
    st.title("ğŸ’¬ ChatGPT-like Clone")
    user_first_input = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?", key="initial_input")
    if st.button("â–¶ï¸ ì‹œì‘í•˜ê¸°"):
        if user_first_input:
            st.session_state.messages.append({"role": "user", "content": user_first_input})
            st.experimental_rerun()
    st.markdown('</div>', unsafe_allow_html=True)

# âœ… ì´í›„: ì¼ë°˜ ì±„íŒ… UI
else:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # í”„ë¡¬í”„íŠ¸ ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            try:
                stream = client.chat.completions.create(
                    model=st.session_state["openai_model"],
                    messages=[
                        {"role": m["role"], "content": m["content"]}
                        for m in st.session_state.messages
                    ],
                    stream=True,
                )

                full_response = ""
                placeholder = st.empty()

                for chunk in stream:
                    content = getattr(chunk.choices[0].delta, "content", None)
                    if content:
                        full_response += content
                        placeholder.markdown(full_response)

                st.session_state.messages.append(
                    {"role": "assistant", "content": full_response}
                )

                summary = prompt[:30] + ("..." if len(prompt) > 30 else "")
                st.session_state.history.append({
                    "title": summary,
                    "full": st.session_state.messages.copy()
                })

            except RateLimitError:
                st.error("âš ï¸ ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
