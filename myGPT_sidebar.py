from openai import OpenAI, RateLimitError
import streamlit as st

st.set_page_config(page_title="ChatGPT Clone", layout="wide")

# ğŸ§¼ CSS: ì¤‘ì•™ ì…ë ¥ì°½ìš©, ì…ë ¥ì°½ í­ ì œí•œ
st.markdown("""
    <style>
    .centered-input-container {
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        height: 80vh;
        text-align: center;
    }
    [data-testid="stChatInput"] {
        max-width: 700px;
        margin: 0 auto;
    }
    </style>
""", unsafe_allow_html=True)

# ğŸ“Œ API ì„¤ì •
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ìƒíƒœ ì´ˆê¸°í™”
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-3.5-turbo"
if "messages" not in st.session_state:
    st.session_state.messages = []
if "history" not in st.session_state:
    st.session_state.history = []

# ğŸ”¹ ì‚¬ì´ë“œë°”: ëŒ€í™” ê¸°ë¡
with st.sidebar:
    st.header("ğŸ’¬ ëŒ€í™” ê¸°ë¡")
    if st.session_state.history:
        for i, item in enumerate(st.session_state.history):
            if st.button(item["title"], key=f"history_{i}"):
                st.session_state.messages = item["full"]
                st.experimental_rerun()
    if st.button("ğŸ—‘ï¸ ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.history.clear()
        st.session_state.messages.clear()
        st.experimental_rerun()

# ğŸ”¹ 1. ì²« í™”ë©´ (ëŒ€í™” ì „)
if not st.session_state.messages:
    st.markdown('<div class="centered-input-container">', unsafe_allow_html=True)
    st.title("ğŸ’¬ ChatGPT-like Clone")
    st.subheader("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?")
    user_input = st.chat_input("ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”...")
    st.markdown('</div>', unsafe_allow_html=True)

    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        st.experimental_rerun()

# ğŸ”¹ 2. ì±„íŒ… í™”ë©´ (ëŒ€í™” ì‹œì‘ í›„)
else:
    # ì´ì „ ë©”ì‹œì§€ ë Œë”ë§
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì…ë ¥ ë°›ê¸° (í•˜ë‹¨ ê³ ì •)
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            try:
                stream = client.chat.completions.create(
                    model=st.session_state["openai_model"],
                    messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
                    stream=True,
                )
                full_response = ""
                placeholder = st.empty()
                for chunk in stream:
                    content = getattr(chunk.choices[0].delta, "content", None)
                    if content:
                        full_response += content
                        placeholder.markdown(full_response)

                # ì‘ë‹µ ì €ì¥
                st.session_state.messages.append({"role": "assistant", "content": full_response})

                # ìš”ì•½ ì €ì¥
                summary = prompt[:30] + ("..." if len(prompt) > 30 else "")
                st.session_state.history.append({
                    "title": summary,
                    "full": st.session_state.messages.copy()
                })

            except RateLimitError:
                st.error("âš ï¸ ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
